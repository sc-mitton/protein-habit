{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install chromadb\n",
    "%pip install onnxruntime-gpu\n",
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "print(onnxruntime.get_available_providers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import time\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.utils.embedding_functions import ONNXMiniLM_L6_V2\n",
    "\n",
    "cuda_ef = ONNXMiniLM_L6_V2(preferred_providers=['CUDAExecutionProvider'])\n",
    "ef = ONNXMiniLM_L6_V2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CoreMLExecutionProvider', 'AzureExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "print(onnxruntime.get_available_providers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/scmitton/Documents/Dev/protein-count/fast-api/db/CompFood.sqlite\n"
     ]
    }
   ],
   "source": [
    "db_path = os.getcwd() + \"/CompFood.sqlite\"\n",
    "print(db_path)\n",
    "conn = sqlite3.connect(db_path)\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('usda_non_branded_column',), ('usda_branded_column',), ('menustat',)]\n"
     ]
    }
   ],
   "source": [
    "print(conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def producer(batch_size, queue):\n",
    "    '''\n",
    "    Iterates throught the rows of the usda_non_branded_column, usda_branded_column, and menustat table\n",
    "    and adds them to the queue in batches of size batch_size\n",
    "    '''\n",
    "    documents = []\n",
    "    ids = []\n",
    "    metadatas = []\n",
    "\n",
    "    # -------------------------- Embed Non-Branded Foods ------------------------- #\n",
    "\n",
    "    df = pd.read_sql_query(\"SELECT * FROM usda_non_branded_column;\", conn)\n",
    "\n",
    "    # Process and transform\n",
    "    df = df.drop_duplicates(subset=['fdc_id']).dropna(subset=['description'])\n",
    "    df['fdc_id'] = df['fdc_id'].astype(str) # Change id to str\n",
    "    meta_columns = [\n",
    "        'protein_amount', 'energy_amount', 'carb_amount',\n",
    "        'fat_amount', 'serving_size'\n",
    "    ]\n",
    "    df = df.dropna(subset=meta_columns) # Clear rows with null values in any meta_column\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        documents.append(row['description'])\n",
    "        ids.append(row['fdc_id'])\n",
    "        metadatas.append(row[meta_columns].to_dict())\n",
    "        # Empty buffer\n",
    "        if len(ids) > batch_size:\n",
    "            queue.put((ids, documents, metadatas))\n",
    "            ids, documents, metadatas = [], [], []\n",
    "\n",
    "    # ---------------------------- Embed Branded Foods --------------------------- #\n",
    "\n",
    "    df = pd.read_sql_query(\"SELECT * FROM usda_branded_column;\", conn)\n",
    "\n",
    "    # Process and transform\n",
    "    df = df.drop_duplicates(subset=['fdc_id']).dropna(subset=['description'])\n",
    "    df['fdc_id'] = df['fdc_id'].astype(str) # Change id to str\n",
    "    meta_columns += ['brand_name']\n",
    "    df = df.dropna(subset=meta_columns) # Clear rows with null values in any meta_column\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        documents.append(row['description'])\n",
    "        ids.append(row['fdc_id'])\n",
    "        metadatas.append(row[meta_columns].to_dict())\n",
    "        # Empty buffer\n",
    "        if len(ids) > batch_size:\n",
    "            queue.put((ids, documents, metadatas))\n",
    "            ids, documents, metadatas = [], [], []\n",
    "\n",
    "    if len(ids) > 0:\n",
    "        queue.put((ids, documents, metadatas))\n",
    "        ids, documents, metadatas = [], [], []\n",
    "\n",
    "    # ---------------------------- Embed Menu Foods ---------------------------- #\n",
    "\n",
    "    df = pd.read_sql_query(\"SELECT * FROM menustat;\", conn)\n",
    "    df = df.drop_duplicates(subset=['menustat_id']).dropna(\n",
    "        subset=['description', 'restaurant'])\n",
    "    df['menustat_id'] = df['menustat_id'].astype(str) # Change id to str\n",
    "    df = df[df['food_category'] != 'Beverages'] # Filter beverages\n",
    "    df['description'] = df['restaurant'] + ' ' + df['item_description']\n",
    "\n",
    "    columns = ['protein', 'energy', 'carbs', 'fat']\n",
    "    for col in columns:\n",
    "        amount_column = col.strip('s') + '_amount'\n",
    "        grams_column = col + '_per_100g'\n",
    "\n",
    "        # Filter nulls\n",
    "        df = df.dropna(subset=[grams_column, 'serving_size'])\n",
    "\n",
    "        # Convert to int\n",
    "        df[grams_column] = df[grams_column].astype(float)\n",
    "        df['serving_size'] = df['serving_size'].astype(float)\n",
    "\n",
    "        # Calculate amount\n",
    "        df[amount_column] = df[grams_column] * df['serving_size'] / 100.0\n",
    "\n",
    "    meta_columns = ['protein_amount', 'energy_amount', 'carb_amount',\n",
    "                    'fat_amount', 'serving_size', 'restaurant']\n",
    "\n",
    "    # Clear rows with null values in any meta_column\n",
    "    df = df.dropna(subset=meta_columns)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        documents.append(row['description'])\n",
    "        ids.append(row['menustat_id'])\n",
    "        metadatas.append(row[meta_columns].to_dict())\n",
    "        # Empty buffer\n",
    "        if len(ids) > batch_size:\n",
    "            queue.put((ids, documents, metadatas))\n",
    "            ids, documents, metadatas = [], [], []\n",
    "\n",
    "    if len(ids) > 0:\n",
    "        queue.put((ids, documents, metadatas))\n",
    "\n",
    "def consumer(use_cuda, queue):\n",
    "    client = chromadb.PersistentClient(path='./chroma')\n",
    "    device = \"cuda\" if use_cuda else \"cpu\"\n",
    "    print(f\"Using device: {device}\")\n",
    "    current_batch = 0\n",
    "\n",
    "    embedding_function = cuda_ef if use_cuda else ef\n",
    "\n",
    "    collection = client.get_collection(\n",
    "        name='foods', embedding_function=embedding_function)\n",
    "\n",
    "    while True:\n",
    "        # Check for items in queue, this process blocks until queue has items to process.\n",
    "        if queue.empty():\n",
    "            if current_batch > 1:\n",
    "                print('\\r', end='', flush=True)\n",
    "                print('Consumer currently blocked', end='', flush=True)\n",
    "        batch = queue.get()\n",
    "\n",
    "        if batch is None:\n",
    "            break\n",
    "\n",
    "        if current_batch > 1:\n",
    "            print(f\"\\rProcessing batch {current_batch} of {len(batch[0])} items\", end=\"\", flush=True)\n",
    "        else:\n",
    "            print(f\"Processing batch {current_batch} of {len(batch[0])} items\", end=\"\", flush=True)\n",
    "\n",
    "        collection.add(\n",
    "            ids=batch[0],\n",
    "            documents=batch[1],\n",
    "            metadatas=batch[2]\n",
    "        )\n",
    "        current_batch += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: CPU\n",
      "Deleting collection...\n",
      "Creating collection...\n",
      "Starting producer...\n",
      "Starting consumer...\n",
      "\n",
      "Finished!\n",
      "Time taken: 0.04242110252380371 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/scmitton/.pyenv/versions/3.11.8/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "  File \"/Users/scmitton/.pyenv/versions/3.11.8/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "                            ^ ^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^  File \"/Users/scmitton/.pyenv/versions/3.11.8/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "^^^^\n",
      "  File \"/Users/scmitton/.pyenv/versions/3.11.8/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "                  ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^AttributeError: Can't get attribute 'producer' on <module '__main__' (built-in)>^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'consumer' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "client = chromadb.PersistentClient(path='./chroma')\n",
    "use_cuda = onnxruntime.get_device() == \"CUDA\" # Check if cuda is available\n",
    "print(f\"Using device: {onnxruntime.get_device()}\")\n",
    "embedding_function = cuda_ef if use_cuda else ef\n",
    "\n",
    "try:\n",
    "    collection = client.get_collection(name=\"foods\")\n",
    "    if collection:\n",
    "        print(\"Deleting collection...\")\n",
    "        client.delete_collection(name=\"foods\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print(\"Creating collection...\")\n",
    "client.create_collection(\n",
    "    name=\"foods\", embedding_function=embedding_function)\n",
    "\n",
    "# For cleaner reloading, delete and re-create the collections\n",
    "queue = mp.Queue()\n",
    "\n",
    "# Create producer and consumer processes.\n",
    "producer_process = mp.Process(target=producer, args=(batch_size, queue))\n",
    "consumer_process = mp.Process(target=consumer, args=(True, queue))\n",
    "\n",
    "# Start processes\n",
    "print(\"Starting producer...\")\n",
    "producer_process.start()\n",
    "print(\"Starting consumer...\")\n",
    "consumer_process.start()\n",
    "\n",
    "tik = time.time()\n",
    "\n",
    "# Wait for producer to finish producing\n",
    "producer_process.join()\n",
    "\n",
    "# Signal consumer to stop consuming by putting None into the queue. Need 2 None's to stop 2 consumers.\n",
    "queue.put(None)\n",
    "\n",
    "# Wait for consumer to finish consuming\n",
    "consumer_process.join()\n",
    "\n",
    "tok = time.time()\n",
    "print('\\nFinished!')\n",
    "print(f\"Time taken: {tok - tik} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
